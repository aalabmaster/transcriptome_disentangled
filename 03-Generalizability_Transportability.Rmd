
---
title: "Generalizability and Transportability of Transcriptome Prediction"
author: "Amir Asiaee"
date: '`r Sys.Date()`'
output:
  html_document:
    highlight: kate
    theme: yeti
    toc: yes
---

```{r globopt, echo=FALSE}
knitr::opts_chunk$set(fig.width=12) 
```

```{r mycss, results="asis", echo=FALSE}
cat('
<style type="text/css">
b, strong {color: red; }
i, em {color: blue; }
.defn {color: purple; }
.para {color: purple;
      font-weight: bold;
}
.figure { text-align: center; }
.caption { font-weight: bold; }
</style>
')
```

# Getting Started
```{r globals}
rm(list=ls())
source("00-paths.R")
ls()
```

Load both mRNA and miR data:
```{r loadData, warning = FALSE}
f <- file.path(paths$clean, "noGBMmatchedData.Rda")
if (file.exists(f)) {
  load(f)
} else {
  load(file = file.path(paths$clean, "matchedData.Rda"))
  discard <- which(cancerType == 'GBM')
  mRNAdata <- mRNAdata[, -discard]
  miRdata <- miRdata[, -discard]
  save(mRNAdata, miRdata, file = f)
}
dim(mRNAdata)
dim(miRdata)
rm(discard, f)
gc()
```

Separate TF from mRNAs that we want to predict:
```{r load tfs, warning = FALSE}
f <- file.path(paths$scratch, 'tfdata.Rda')
g <- file.path(paths$scratch, 'mrnaRestdata.Rda')
if (file.exists(f)) {
  load(f)
  load(g)
} else {
  htf <- read.csv(file = file.path(paths$clean, "HumanTF.csv"))
  tfSymbols <- htf$Hs.SYMBOL
  tfSymbols <- tfSymbols[!is.na(tfSymbols)]
  sum(tfSymbols %in% rownames(mRNAdata))
  tfdata <- mRNAdata[(rownames(mRNAdata) %in% tfSymbols), ]
  mRNARest <- mRNAdata[!(rownames(mRNAdata) %in% tfSymbols), ]
  save(tfdata, file = f)
  save(mRNARest, file = g)
}
dim(tfdata)
dim(mRNARest)

rm(mRNAdata, f, g, tfSymbols, sampleType, htf)
gc()
```
# Cross-Validation for Model Complexity Selection

## Saving Train and Test Batches for Cross Validation
Adding fold variable to each sample and saving train/test portions for the whole analysis: 
```{r fold, warning = FALSE}
f <- file.path(paths$scratch, paste('train_batch_', 1, '.Rda', sep = ''))
nfolds <- 5
if (!file.exists(f)) {
  foldsId <- rep(1:nfolds, length.out = ncol(mRNARest))
  for (k in 1:nfolds) {
    print(paste("Fold", k, "started."))
    index <- which(foldsId == k)
    f <- file.path(paths$scratch, paste('train_batch_', k, '.Rda', sep = ''))
    g <- file.path(paths$scratch, paste('test_batch_', k, '.Rda', sep = ''))
  
  
    tfTrain <- tfdata[,-index]; tfTest <- tfdata[,index];
    mirTrain <- miRdata[,-index]; mirTest <- miRdata[,index];
    mrnaTrain <- mRNARest[,-index]; mrnaTest <- mRNARest[,index];
    
    save(tfTrain, mirTrain, mrnaTrain, file = f)
    save(tfTest, mirTest, mrnaTest, file = g)
  }
}
rm(mRNARest, miRdata, tfdata)
rm(mirTest, mirTrain, mrnaTest, mrnaTrain, tfTest, tfTrain, foldsId, f, g, index, k)
gc()
```

## Variable Selection with Thresher
Variable selection:
```{r tresh tfs, warning = FALSE}
suppressMessages( library(Thresher) ) # brings along PCDimension automatically

f <- file.path(paths$scratch, paste('thresh_reap_miR_', 5, '.Rda', sep = ''))

if (!file.exists(f)) {
  set.seed(47053)
  for (k in 1:nfolds) {
    print(paste("Fold", k, "threshing started."))
    load(file.path(paths$scratch, paste('train_batch_', k, '.Rda', sep = '')))
    rm(mrnaTrain)
    
    print(paste("Thresher for TFs"))
    startTime <- Sys.time()
    Thresh <- Thresher(t(tfTrain), method = "auer.gervini",
                       scale = TRUE, agfun = agDimTwiceMean)
    Reap <- Reaper(Thresh, useLoadings = TRUE, cutoff = 0.35, 
                   metric = NULL, linkage = "ward.D2", maxSampleGroups = 486)
    f <- file.path(paths$scratch, paste('thresh_reap_tf_', k, '.Rda', sep = ''))
    save(Thresh, Reap, file = f)
    print(Sys.time() - startTime)
    
    print(paste("Thresher for miRs"))
    startTime <- Sys.time()
    nonzero <- apply(mirTrain, 1, function(x) sum(x != 0))
    cutoff <- 0.25 * ncol(mirTrain)
    filteredMir <- mirTrain[nonzero > cutoff, ]

    Thresh <- Thresher(t(filteredMir), method = "auer.gervini",
                       scale = TRUE, agfun = agDimTwiceMean)
    Reap <- Reaper(Thresh, useLoadings = TRUE, cutoff = 0.35,
                   metric = NULL, linkage = "ward.D2", maxSampleGroups = 486)
    f <- file.path(paths$scratch, paste('thresh_reap_miR_', k, '.Rda', sep = ''))
    save(Thresh, Reap, file = f)
    print(Sys.time() - startTime)
  }
}
rm(f, Thresh, Reap, cutoff, nonzero, filteredMir, tfTrain, mirTrain)
gc()
```

## Medoid Computation
We need to save the medoids: 
```{r save tf mediods, warning = FALSE}

f <- file.path(paths$scratch, paste('medoids_mir_', 5, '.Rda', sep = ''))

if (!file.exists(f)) {
  set.seed(41053)
  for (k in 1:nfolds) {
    print(paste("Fold", k, "mediod finding started."))
    load(file.path(paths$scratch, paste('train_batch_', k, '.Rda', sep = '')))
    rm(mrnaTrain)
    
    load(file.path(paths$scratch, paste('thresh_reap_tf_', k, '.Rda', sep = '')))
    groups <- predict(Reap@fit)
    names(groups) <- rownames(tfTrain)[Reap@keep]
    NG <- Reap@nGroups
    tfMedoid <- matrix(0, ncol(tfTrain), NG)
    colnames(tfMedoid) <- 1:ncol(tfMedoid)
    d2MeanList <- list()
    for (I in 1:NG) {
      clusterExp <- tfTrain[names(groups)[groups == I], ]
      meanZeroClusterExp <- sweep(clusterExp, 2, apply(clusterExp, 2, mean))
      d2Mean <- apply(meanZeroClusterExp, 1, function(x) {sqrt(sum(x * x))})
      medoidGene <- rownames(clusterExp)[which.min(d2Mean)]
      tfMedoid[, I] <- tfTrain[medoidGene, ]
      colnames(tfMedoid)[I] <- medoidGene
      d2MeanList[[I]] <- d2Mean
    }
    f <- file.path(paths$scratch, paste('medoids_tf_', k, '.Rda', sep = ''))
    save(tfMedoid, file = f)
    f <- file.path(paths$scratch, paste('d2MeanList_tf_', k, '.Rda', sep = ''))
    save(d2MeanList, file = f)



    load(file.path(paths$scratch, paste('thresh_reap_miR_', k, '.Rda', sep = '')))
    nonzero <- apply(mirTrain, 1, function(x) sum(x != 0))
    cutoff <- 0.25 * ncol(mirTrain)
    filteredMir <- mirTrain[nonzero > cutoff, ]
    
    groups <- predict(Reap@fit)
    names(groups) <- rownames(filteredMir)[Reap@keep]
    NG <- Reap@nGroups
    mirMedoid <- matrix(0, ncol(filteredMir), NG)
    colnames(mirMedoid) <- 1:ncol(mirMedoid)
    d2MeanList <- list()
    for (I in 1:NG) {
      clusterExp <- filteredMir[names(groups)[groups == I], ]
      meanZeroClusterExp <- sweep(clusterExp, 2, apply(clusterExp, 2, mean))
      d2Mean <- apply(meanZeroClusterExp, 1, function(x) {sqrt(sum(x * x))})
      medoidGene <- rownames(clusterExp)[which.min(d2Mean)]
      mirMedoid[, I] <- filteredMir[medoidGene, ]
      colnames(mirMedoid)[I] <- medoidGene
      d2MeanList[[I]] <- d2Mean
    }
    f <- file.path(paths$scratch, paste('medoids_mir_', k, '.Rda', sep = ''))
    save(mirMedoid, file = f)
    f <- file.path(paths$scratch, paste('d2MeanList_mir_', k, '.Rda', sep = ''))
    save(d2MeanList, file = f)
  }
}
rm(f, tfMedoid, mirMedoid, groups, NG, d2MeanList, clusterExp, meanZeroClusterExp, d2Mean, medoidGene)
rm(nonzero, startTime, I, k, cutoff)
```

## Pseudo-Tissue (Cluster) Aware Linear Model 
Next, we fit the linear models for each tissue after mean zeroing the outcome (this is equivalent to fit a model to all tissue and then fit the residuals of that model per tissue). 

###Train
First the training part:
```{r helpers, warning = FALSE, echo=FALSE}
library(ClassComparison)
library(oompaBase)

computeCor <- function(res, Y, ns=10^4){
  Yhat <- Y - res
  M <- nrow(Y)
  Ours <- sapply(1:M, function(i) cor(Y[i,], Yhat[i,]))
  
  Yind <- sample(1:M, ns, replace = T)
  YhatInd <- sample(1:M, ns, replace = T)
  ind <- cbind(Yind, YhatInd)
  ind <- ind[Yind != YhatInd, ]
  Null <- sapply(1:nrow(ind), function(j) cor(Y[ind[j,1],], Yhat[ind[j,2],]))
  z <- quantile(Null, .95, na.rm = T)
  acc <- sum(Ours > z, na.rm = T) / M
  return(list(ours=Ours, null=Null, acc=acc))
}


computeR2 <- function(res, Y){
  M <- ncol(Y)
  dmean <- matrixMean(Y)
  dvar <- as.vector(matrixVar(Y, dmean))
  ssres <- apply(res ^ 2, 1, sum)
  r2 <- rep(0, M)
  # varInd <- dvar != 0
  # r2[varInd] <- 1 - ssres[varInd] / (dvar[varInd] * (M - 1))
  r2 <- 1 - ssres / (dvar * (M - 1))
  return(r2)
}

```

```{r training, warning = FALSE}
trainClusterAware <- function(X, Y, nc){
  coeffMatList <- list()
  N <- nrow(X); M <- nrow(Y); P <- ncol(X);
  res <- matrix(0, nrow = M, ncol = N)
  cat(paste("\n  Trianing with ", nc, " clusters:"))
  cat("\n    1) Clustering")
  myClust <- kmeans(X, nc, iter.max = 100, nstart = 100)
  assignment <- myClust$cluster

  cat("\n    2) Regression")
  cat("\n      Fitting OLS to clusters 1")
  for (cluster in 1:nc) {
    if(cluster %% 5 == 0) cat(paste(cluster)) else cat('.')
    coeffMat <- matrix(0, nrow = P + 1, ncol = M, 
                       dimnames = list(c('(Intercept)',
                                         gsub('\\-', '.', colnames(X))), 
                                         rownames(Y)))
    
    S <- (assignment == cluster) #Cluster Selector
    #remove constant covariates
    varCov <- apply(X[S,], 2, var) != 0
    Xs <- X[S, varCov]
    Ys <- Y[, S]
    
    if (nrow(Xs) < ncol(Xs)) {
      #Not enough samples per cluster
      #Per-cluster average is our predictor
      #YcAvg is our predictions and the residuals are mean0Yc
      # pred[, S] <- matrix(rep(YcAvg, S), ncol = S)
      coeffMat[1,] <- apply(Ys, 1, mean)#YcAvg 
      res[, S] <- sweep(Ys, 1, coeffMat[1,])#mean0Yc 
    } else{
      mlm <- MultiLinearModel(Y ~ ., Xs, Ys)
      # pred[, S] <- t(mlm@predictions)
      coeffMat[rownames(mlm@coefficients),] <- mlm@coefficients
      res[, S] <- Ys - t(mlm@predictions)
    }
    coeffMatList[[cluster]] <- coeffMat
  } 
  
  r2 <- computeR2(res, Y)
  # hist(r2, breaks=123)
  cat(paste("\n      Average R2:", round(mean(r2, na.rm =T), 2)))
  rmse <- sqrt((1/N) * apply(res ^ 2, 1, sum))
  cat(paste("\n      Averge RMSE:", round(mean(rmse),2)))
  corr <- computeCor(res, Y)
  cat(paste("\n      Averge Cor:", round(mean(corr$acc),2)))
  
  trained <- list(coeffMatList=coeffMatList, nc=nc, 
                  res=res, r2=r2, rmse=rmse, corr=corr,
                  centers=myClust$centers)
  save(trained, file = file.path(paths$scratch, paste('trained_', nc, '.Rda', sep = '')))
  
  return(trained)
}


```
Note that we do not save the whole MLM object, we just keep the coefficient matrix and the performance metrics that we keep track of: R2, RMSE, and Correlation of the prediction with outcome. We also keep the number of clusters and the cluster centers for the testing phase. 

### Test
Next testing: First for each new test data we find the closest cluster center from the training and then we use the corresponding linear model for prediction. Note that R2 here is not a valid measure because it may become arbitrarily small since any predictive model trained on training data can do worse than the test data mean. So we only compute RMSE and Correlation performances. 
 
```{r test, warning = FALSE}
testClusterAware <- function(X, Y, model){
  centers <- model$centers
  cat(paste("\n  Testing with ", nrow(centers), " clusters:"))
  M <- nrow(Y); N <- ncol(Y); #nrow(X) == N
  D <- matrix(0, nrow = N, ncol = nrow(centers))
  for(i in 1:nrow(centers)){
    center <- centers[i, ]
    D[,i] <- apply(X, 1, function(x) sum((x - center)^2))
  }
  C <- apply(D, 1, which.min)
  
  res <- matrix(0, nrow = M, ncol = N)
  aX <- cbind(rep(1, nrow(X)), X) #augmented X
  for(i in 1:nrow(centers)){
    res[, C==i] <- Y[,C==i] - t(aX[C==i, ] %*% model$coeffMatList[[i]])
  }
  rmse <- sqrt((1/N) * apply(res ^ 2, 1, sum))
  cat(paste("\n    Averge RMSE:", round(mean(rmse),2)))
  corr <- computeCor(res, Y)
  # cat(paste("\n    Averge Cor:", round(mean(corr$acc),2)))
  cat(paste("\n    Averge Cor:", round((corr$acc),2)))


  tested <- list(res=res, rmse=rmse, corr=corr)
  save(tested, file = file.path(paths$scratch, paste('tested_', model$nc, '.Rda', sep = '')))
  
  return(tested)
}
```

### Cross-Validation
Finally, we run the model:

```{r mirMLM, warning = FALSE}
nClusters <- c(1, 5, 10, 15, 20, 25, 30, 35)

f <- file.path(paths$scratch, paste('fold_', 5, '_kmeans_', 
                                          35, '.Rda', sep = ''))
if (!file.exists(f)) {
  set.seed(41053)

  for (k in 1:nfolds) {
    cat(paste("\nFold ", k, ": ", sep = ''))
    # Load Training Samples (tfTrain, mirTrain, mrnaTrain)
    load(file.path(paths$scratch, paste('train_batch_', k, '.Rda', sep = '')))
    rm(tfTrain, mirTrain)
    ## Global mean removal for Data Sharing
    Yavg <- apply(mrnaTrain, 1, mean)
    mean0Y <- sweep(mrnaTrain, 1, Yavg)
    ## Load Selected Features
    load(file.path(paths$scratch, paste('medoids_tf_', k, '.Rda', sep = '')))
    load(file.path(paths$scratch, paste('medoids_mir_', k, '.Rda', sep = '')))
    X <- cbind(tfMedoid, mirMedoid)
    cat(paste("Dimensions of X is", paste(dim(X), collapse = '*')))
    # Load Test Samples (tfTest, mirTest, mrnaTest)
    load(file.path(paths$scratch, paste('test_batch_', k, '.Rda', sep = '')))
    ## Prepare Test Features (match with the selected features of training set)
    tfTestMedoid <- t(tfTest[colnames(tfMedoid), ])
    mirTestMedoid <- t(mirTest[colnames(mirMedoid),])
    Xt <- cbind(tfTestMedoid, mirTestMedoid)
    mean0Yt <- sweep(mrnaTest, 1, Yavg)
    
    cnt <- 0
    for(nc in nClusters){
      cnt <- cnt + 1
      #Train
      learned <- trainClusterAware(X, mean0Y, nc)
      #Test
      tested <- testClusterAware(Xt, mean0Yt, learned)
      #Save
      cvTable[k, cnt] <- mean(tested$rmse)
      f <- file.path(paths$scratch, paste('fold_', k, '_kmeans_', 
                                          nc, '.Rda', sep = ''))
      cat(paste("\nSaving results of", nc, "clusters for fold", k))
      save(learned, tested, file = f)
    }
  }
}

rm(f, cvTable, tested, learned, cnt, mean0Yt, Xt, mirTestMedoid, tfTestMedoid, X, mean0Y, Yavg)
rm(nc, k, cnt)
gc()
```
So the best test performance corresponds to 15 clusters. Let's take a look at the train and test results. 

```{r r2res, warning = FALSE}
f <- file.path(paths$scratch, 'cvTables.Rda')
if (file.exists(f)) {
  load(f)
} else{
  cvR2Trn <- cvCorrTst <- cvCorrTrn <- cvRmseTst <- cvRmseTrn <- matrix(0, nrow = nfolds, ncol = length(nClusters))
  colnames(cvR2Trn) <- colnames(cvCorrTst) <- colnames(cvRmseTst) <- paste("nc", nClusters, sep = '-')
  
  cnt <- 0
  for(nc in nClusters){
    cnt <- cnt + 1
    cat(paste("\nNumber of clusters:", nc, "Folds"))
    for (k in 1:nfolds) {
      cat(paste(" ", k))
      f <- file.path(paths$scratch, paste('fold_', k, '_kmeans_', 
                                            nc, '.Rda', sep = ''))
      load(file = f)
      # print(summary(learned$r2))
      # hist(learned$r2, breaks=234, 
      #      main=paste("Number of Clusters=", nc, ",Fold=", k, 
      #                 ",Average R2=", round(stat['Mean'],2)),
      #      xlab = "R2")
      cvR2Trn[k, cnt] <- mean(learned$r2, na.rm=TRUE)
      cvRmseTst[k, cnt] <- mean(tested$rmse)
      cvRmseTrn[k, cnt] <- mean(learned$rmse) 
      cvCorrTst[k, cnt] <- mean(tested$corr$acc)
      cvCorrTrn[k, cnt] <- mean(learned$corr$acc)
    }
  }
  save(cvR2Trn, cvCorrTst, cvCorrTrn, cvRmseTst, cvRmseTrn, file=f)
}

print("R2 during training:")
print(cvR2Trn)
print(paste("Average train R2:", paste(round(apply(cvR2Trn, 2, mean),3) , collapse = ',')))

print("RMSE for training:")
print(cvRmseTst)
print(paste("Best number of clusters according to RMSE:", colnames(cvRmseTst)[which.min(apply(cvRmseTst, 2, mean))]))
print(paste("Average test RMSE:", paste(round(apply(cvRmseTst, 2, mean),3), collapse = ',')))

print("Corr for training:")
print(cvCorrTst)
print(paste("Best number of clusters according to Correlation:", colnames(cvCorrTst)[which.max(apply(cvCorrTst, 2, mean))]))
print(paste("Average test Corr:", paste(round(apply(cvCorrTst, 2, mean),4), collapse = ',')))

rm(cnt, f)
```
We get average of 69% R2, which is pretty good! The test correlation performance is also excellent! 

```{r plot, warning = FALSE}
library(ggplot2)

plot.cv <- function(cvtrain, cvtest, ytext){
  yt <- colMeans(cvtest)
  et <- apply(cvtest, 2, sd)
  
  yn <- colMeans(cvtrain)
  en <- apply(cvtrain, 2, sd)
  
  toplot <- data.frame(yt = yt,et = et,yn = yn,en = en,nc = nClusters)
  
  ggplot(toplot) +
    geom_line(aes(x = nc, y = yt, col = "Test"), size = 1) +
    geom_point(aes(x = nc, y = yt, shape = 'a'), show.legend = FALSE) +
    geom_line(aes(x = nc, y = yn, col = "Train"), size = 1) +
    geom_point(aes(x = nc, y = yn, shape = 'c'), show.legend = FALSE) +
    geom_errorbar(aes(x = nc,ymin = yt - et,ymax = yt + et), width = 0.5) +
    geom_errorbar(aes(x = nc,ymin = yn - en,ymax = yn + en), width = 0.5) +
    theme_bw() + xlab("Number of Clusters") + ylab(ytext) +
    scale_color_manual(values = c("red", "green"), name = "")
}

load(file.path(paths$scratch, 'cvTables.Rda'))

plot.cv(cvRmseTrn, cvRmseTst, "RMSE")
plot.cv(cvCorrTrn, cvCorrTst, "Correlation")


toplotr2 <- data.frame(yt = colMeans(cvR2Trn),
                       et = apply(cvR2Trn, 2, sd),nc = nClusters)
ggplot(toplotr2) +
    geom_line(aes(x = nc, y = yt), size = 1) +
    geom_point(aes(x = nc, y = yt, shape = 'a'), show.legend = FALSE) +
    geom_errorbar(aes(x = nc,ymin = yt - et,ymax = yt + et), width = 0.5) +
    theme_bw() + xlab("Number of Clusters") + ylab("Average R2") 

rm(toplotr2, cvRmseTst, cvRmseTrn, cvCorrTrn, cvCorrTst, cvR2Trn)
```

# Learning the Final Model Using All of Data 
Now that we have selected the model complexity through CV, we train a single model using all of data. Then we test this model by GTEx.


## Load the Relevant Data
```{r bigModel, warning = FALSE}
load(file.path(paths$clean, "noGBMmatchedData.Rda"))
dim(miRdata)
rm(mRNAdata)
load(file.path(paths$scratch, 'tfdata.Rda'))
dim(tfdata)
load(file.path(paths$scratch, 'mrnaRestdata.Rda'))
dim(mRNARest)
```

## Thresher
```{r all thresher, warning = FALSE}
suppressMessages( library(Thresher) ) # brings along PCDimension automatically

f <- file.path(paths$scratch, paste('thresh_reap_tf_all.Rda', sep = ''))
g <- file.path(paths$scratch, paste('thresh_reap_miR_all.Rda', sep = ''))


if (!file.exists(f)) {
  set.seed(47053)
  print(paste("Thresher for TFs"))
  Thresh <- Thresher(t(tfdata), method = "auer.gervini",
                     scale = TRUE, agfun = agDimTwiceMean)
  Reap <- Reaper(Thresh, useLoadings = TRUE, cutoff = 0.35, 
                 metric = NULL, linkage = "ward.D2", maxSampleGroups = 486)
  save(Thresh, Reap, file = f)

  print(paste("Thresher for miRs"))
  nonzero <- apply(miRdata, 1, function(x) sum(x != 0))
  cutoff <- 0.25 * ncol(miRdata)
  filteredMir <- miRdata[nonzero > cutoff, ]

  Thresh <- Thresher(t(filteredMir), method = "auer.gervini",
                     scale = TRUE, agfun = agDimTwiceMean)
  Reap <- Reaper(Thresh, useLoadings = TRUE, cutoff = 0.35,
                 metric = NULL, linkage = "ward.D2", maxSampleGroups = 486)
  save(Thresh, Reap, file = g)
}

```

## Medoid

```{r all Medoids, warning = FALSE}
f <- file.path(paths$scratch, paste('medoids_tf_all.Rda', sep = ''))
g <- file.path(paths$scratch, paste('medoids_mir_all.Rda', sep = ''))

if (!file.exists(f)) {
  set.seed(41053)
  load(file.path(paths$scratch, paste('thresh_reap_tf_all.Rda', sep = '')))
  groups <- predict(Reap@fit)
  names(groups) <- rownames(tfdata)[Reap@keep]
  NG <- Reap@nGroups
  tfMedoid <- matrix(0, ncol(tfdata), NG)
  colnames(tfMedoid) <- 1:ncol(tfMedoid)
  d2MeanList <- list()
  for (I in 1:NG) {
    clusterExp <- tfdata[names(groups)[groups == I], ]
    meanZeroClusterExp <- sweep(clusterExp, 2, apply(clusterExp, 2, mean))
    d2Mean <- apply(meanZeroClusterExp, 1, function(x) {sqrt(sum(x * x))})
    medoidGene <- rownames(clusterExp)[which.min(d2Mean)]
    tfMedoid[, I] <- tfdata[medoidGene, ]
    colnames(tfMedoid)[I] <- medoidGene
    d2MeanList[[I]] <- d2Mean
  }
  save(tfMedoid, file = f)
  h <- file.path(paths$scratch, paste('d2MeanList_tf_all.Rda', sep = ''))
  save(d2MeanList, file = h)



  load(file.path(paths$scratch, paste('thresh_reap_miR_all.Rda', sep = '')))
  nonzero <- apply(miRdata, 1, function(x) sum(x != 0))
  cutoff <- 0.25 * ncol(miRdata)
  filteredMir <- miRdata[nonzero > cutoff, ]
  
  groups <- predict(Reap@fit)
  names(groups) <- rownames(filteredMir)[Reap@keep]
  NG <- Reap@nGroups
  mirMedoid <- matrix(0, ncol(filteredMir), NG)
  colnames(mirMedoid) <- 1:ncol(mirMedoid)
  d2MeanList <- list()
  for (I in 1:NG) {
    clusterExp <- filteredMir[names(groups)[groups == I], ]
    meanZeroClusterExp <- sweep(clusterExp, 2, apply(clusterExp, 2, mean))
    d2Mean <- apply(meanZeroClusterExp, 1, function(x) {sqrt(sum(x * x))})
    medoidGene <- rownames(clusterExp)[which.min(d2Mean)]
    mirMedoid[, I] <- filteredMir[medoidGene, ]
    colnames(mirMedoid)[I] <- medoidGene
    d2MeanList[[I]] <- d2Mean
  }
  save(mirMedoid, file = g)
  h <- file.path(paths$scratch, paste('d2MeanList_mir_all.Rda', sep = ''))
  save(d2MeanList, file = h)
  
} else{
  load(f)
  load(g)
}
rm(f, groups, NG, d2MeanList, clusterExp, meanZeroClusterExp, d2Mean, medoidGene)
rm(nonzero, startTime, I, k, cutoff, filteredMir, miRdata, Reap, Thresh, tfdata)

```

## Regression
```{r , warning = FALSE}
nc <- 15
f <- file.path(paths$scratch, paste('final_model_', nc, '.Rda', sep = ''))
if (!file.exists(f)) {
  Yavg <- apply(mRNARest, 1, mean)
  Y <- sweep(mRNARest, 1, Yavg)
  X <- cbind(tfMedoid, mirMedoid)
  
  coeffMatList <- list()
  N <- nrow(X); M <- nrow(Y); P <- ncol(X);
  res <- matrix(0, nrow = M, ncol = N)
  
  cat(paste("\n  Learning a model with ", nc, " clusters:"))
  cat("\n    1) Clustering")
  myClust <- kmeans(X, nc, iter.max = 100, nstart = 100)
  assignment <- myClust$cluster
  
  cat("\n    2) Regression")
  cat("\n      Fitting OLS to clusters 1")
  
  for (cluster in 1:nc) {
    if(cluster %% 5 == 0) cat(paste(cluster)) else cat('.')
    coeffMat <- matrix(0, nrow = P + 1, ncol = M, 
                       dimnames = list(c('(Intercept)',
                                         gsub('\\-', '.', colnames(X))), 
                                         rownames(Y)))
    
    S <- (assignment == cluster) #Cluster Selector
    varCov <- apply(X[S,], 2, var) != 0
    Xs <- X[S, varCov]
    Ys <- Y[, S]
    
    if (nrow(Xs) < ncol(Xs)) {
      print("Not enough samples, using the means.")
      coeffMat[1,] <- apply(Ys, 1, mean)#YcAvg 
      res[, S] <- sweep(Ys, 1, coeffMat[1,])#mean0Yc 
    } else{
      mlm <- MultiLinearModel(Y ~ ., Xs, Ys)
      coeffMat[rownames(mlm@coefficients),] <- mlm@coefficients
      res[, S] <- Ys - t(mlm@predictions)
    }
    coeffMatList[[cluster]] <- coeffMat
  } 
  
  r2 <- computeR2(res, Y)
  cat(paste("\n      Average R2:", round(mean(r2, na.rm =T), 2)))
  rmse <- sqrt((1/N) * apply(res ^ 2, 1, sum))
  cat(paste("\n      Averge RMSE:", round(mean(rmse),2)))
  corr <- computeCor(res, Y)
  cat(paste("\n      Averge Cor:", round(mean(corr$acc),2)))
  
  model <- list(coeffMatList=coeffMatList, nc=nc, 
                  res=res, r2=r2, rmse=rmse, corr=corr,
                  centers=myClust$centers, alpha=Yavg)
  save(model, file = f)
} else {
  load(f)
}

hist(model$r2, breaks=123, main="R2", xlab=paste("Average R2 =", round(mean(model$r2, na.rm =T), 2)))
print(paste("\n      Average R2:", round(mean(model$r2, na.rm =T), 2)))
rm(coeffMat, coeffMatList, mlm, res, r2, rmse, corr, Yavg, myClust, Y, Ys, X, Xs)
```

## Testing on GTEx

### GTEx Loading
I've done a version of this analysis in `71-r2onGtexSeparatelyNormalized.Rmd` refer to that for a more detail description. In summary, the miR and mRNA (including TFs) data are separately normalized in the TCGA and used from the beginning of our analysis. But this is not the case in GTEx and the raw counts of everything (mRNA, lnRNA, miR, etc.) is given together in a file (so I assume they have been measured in a same way). My preliminary analysis shows that if I normalze the raw counts of GTEx at once the model does not transfer at all (no wonder). So I need to normalize the mRNA and miRNAs separately. 

Below, we load and separately normalize mRNA and miRNA data and then we select the TF and miR medoids from them:

```{r load gtex, warning = FALSE}
gc()
source("00-paths.R")

load(file.path(paths$clean, "ensemble2hg.Rda"))

dim(hg)

```

To avoid any confusion for down the road computation we select the submatrix of the cMat that we have in hg and organize the rows of cMat according to hg:

```{r subset, warning = FALSE}
f <- file.path(paths$scratch, "pMatGtex.Rda")
if (file.exists(f)) {
  load(f)
} else {
  load(file.path(paths$clean, "cMatGtex.Rda"))
  dim(cMat)
  pMat <- cMat[hg$ensembl_gene_id, ]
  save(pMat, file = f)
  rm(cMat)
  gc()
}
dim(pMat)
```

### GTEx mRNA Normalization
Now we Q3 normalize the raw mRNA counts: 
```{r , warning = FALSE}
f <- file.path(paths$scratch, "matchedGtexmRNA_Normalized.Rda")
if (file.exists(f)) {
  load(f)
} else {
  load(file.path(paths$clean, "noGBMmatchedData.Rda"))
  
  namesMrnaAll <- rownames(mRNAdata)
  availmRNAInd <- hg$hgnc_symbol %in% namesMrnaAll
  sum(availmRNAInd)
  
  
  availmRNA <- pMat[availmRNAInd,]
  rownames(availmRNA) <- hg$hgnc_symbol[availmRNAInd]
  
  dim(availmRNA)
  
  matchedGtex <- apply(availmRNA, 2, function(x) log2(1000 * x / quantile(x, .75)+10))
  save(matchedGtex, file = f)
}
  
```

### Selecting TF Medoids

```{r tf mediod selection, warning = FALSE}

f <- file.path(paths$scratch, "gTFMedNorm.Rda")
if (file.exists(f)) {
  load(f)
} else {
  gTFMedNorm <- t(matchedGtex[colnames(tfMedoid), ])
  save(gTFMedNorm, file = f)
}
dim(gTFMedNorm)

```

### miR Medoid Selection

Separate normalization for miRs to RPM. 

```{r mir rpm normalization, warning = FALSE}

f <- file.path(paths$scratch, "matchedGtexmicroRNA_Normalized.Rda")
if (file.exists(f)) {
  load(f)
} else {
  mirInd <- sapply(hg$hgnc_symbol, function(x){ifelse(substr(x, 1, 3) == "MIR" & !grepl("HG", x, fixed = T),TRUE,FALSE)})
  availMir <- pMat[hg$ensembl_gene_id[mirInd],]
  rownames(availMir) <- hg$hgnc_symbol[mirInd]
  matchedMir <- apply(availMir, 2, function(x) log2( ((x*10^6) / sum(x)) + 1))
  save(matchedMir, file = f)
}
rm(pMat)
gc()
```


Selecting miR medoids: First we need to convert the names of selected miRMedoids to the notation available in GTEx. Let's see how many of them are present in GTEx.
```{r mir med selection, warning = FALSE}
converMirNames <- function (longMirs){
  shortMirs <- sapply(longMirs, function(x) substr(x, 9, nchar(x)))
  
  shortMirs <- sapply(shortMirs, function(x) {
    aa <- gregexpr(pattern = '-3p', x)
    index <- aa[[1]][[1]]
    return (ifelse(index != -1, substr(x, 1, index - 1), x))
  })
  
  shortMirs <- sapply(shortMirs, function(x) {
    aa <- gregexpr(pattern = '-5p', x)
    index <- aa[[1]][[1]]
    return (ifelse(index != -1, substr(x, 1, index - 1), x))
  })
  
  shortMirs <-
    sapply(shortMirs, function(x) paste("MIR", x, sep = ""))
  names(shortMirs) <- NULL
  shortMirs <- toupper(shortMirs)
  return(shortMirs)
}
shortMirs <- converMirNames(colnames(mirMedoid))

easyMirs <- intersect(rownames(matchedMir), shortMirs)
save(easyMirs, file = file.path(paths$scratch, "easymirMed.Rda"))

sum(shortMirs %in% rownames(matchedMir))
missingMirs <- shortMirs[!shortMirs %in% rownames(matchedMir)]
print(paste("Missing miRs are", paste(missingMirs, collapse = ', ')))

write.csv(rownames(matchedMir), file=file.path(paths$clean, "matchedMirNames.csv"))
```
We need to do some manual inspection to see if we can find various versions of these miRs before moving forward by looking through all miRs of GTEx saved in `matchedMirNames.csv`.

```{r manual , warning = FALSE}
# Had different name
shortMirs[3] <- 'MIR30C2'
shortMirs[5] <- 'MIR219A1'
shortMirs[12] <- 'MIR125B2'
shortMirs[23] <- 'MIR199A1'

# Next candidate found through manual inspections
shortMirs[2] <- "MIR145"
shortMirs[6] <- "MIR194-1"
shortMirs[10] <- "MIR106B"
shortMirs[13] <- "MIR193B"
shortMirs[14] <- "MIR340"
shortMirs[18] <- "MIR24-2"
```


Finally, miR selection:

```{r mir selection , warning = FALSE}
f <- file.path(paths$scratch, "gmirMedNorm.Rda")

if (file.exists(f)) {
  load(f)
} else {
  gmirMedNorm <- t(matchedMir[shortMirs, ])
  colnames(gmirMedNorm) <- shortMirs
  save(gmirMedNorm, file = f)
}
dim(gmirMedNorm)
```
### Testing

First, load the Y:
```{r const computation, warning = FALSE}
library(ClassComparison)

f <- file.path(paths$scratch, "Ygtex.Rda")
if (file.exists(f)) {
  load(f)
} else {
  load(file.path(paths$scratch, 'mrnaRestdata.Rda'))
  namesMrnaRest <- rownames(mRNARest)
  rm(mRNARest)
  # common ordering of names for future
  Ynames <- intersect(rownames(matchedGtex),namesMrnaRest)
  Ygtex <- matchedGtex[Ynames, ]
  save(Ygtex, Ynames, file = f)
}

length(Ynames)
dim(Ygtex)

```

Load the learned model from TCGA:
```{r model load, warning = FALSE}
load(file.path(paths$scratch, paste('final_model_', 15, '.Rda', sep = '')))
f <- file.path(paths$scratch, paste('gtex_test_normalized', model$nc, '.Rda', sep = ''))

if(!file.exists(f)){
  Y <- sweep(Ygtex, 1, model$alpha[Ynames])
  X <- cbind(gTFMedNorm, gmirMedNorm)
  
  centers <- model$centers
  cat(paste("\n  Testing with ", nrow(centers), " clusters:"))
  M <- nrow(Y); N <- ncol(Y); #nrow(X) == N
  D <- matrix(0, nrow = N, ncol = nrow(centers))
  for(i in 1:nrow(centers)){
    center <- centers[i, ]
    D[,i] <- apply(X, 1, function(x) sum((x - center)^2))
  }
  C <- apply(D, 1, which.min)
  
  res <- matrix(0, nrow = M, ncol = N)
  aX <- cbind(rep(1, nrow(X)), X) #augmented X
  for(i in 1:nrow(centers)){
    print(paste("Cluster", i, "has size", sum(C==i)))
    Beta <- model$coeffMatList[[i]]
    res[, C==i] <- Y[,C==i] - t(aX[C==i, ] %*% Beta[,Ynames])
  }
  rmse <- sqrt((1/N) * apply(res ^ 2, 1, sum))
  cat(paste("\n    Averge RMSE:", round(mean(rmse),2)))
  corr <- computeCor(res, Y)
  cat(paste("\n    Averge Cor:", round((corr$acc),2)))
  gtexResults <- list(res=res, rmse=rmse, corr=corr)
  save(gtexResults, file = f)
} else{
  load(f)
}

cat(paste("\n    Averge RMSE:", round(mean(gtexResults$rmse),2)))
cat(paste("\n    Averge Cor:", round((gtexResults$corr$acc),2)))


```




# Appendix

This analysis was performed using the following R packages.
```{r si}
sessionInfo()

```



