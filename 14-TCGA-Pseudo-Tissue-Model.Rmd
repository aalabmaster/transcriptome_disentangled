---
title: "Train and Test of Pseudo-Tissue Model on TCGA Data"
author: "Amir Asiaee"
date: '`r Sys.Date()`'
output:
  html_document:
    highlight: kate
    theme: yeti
    toc: yes
---

```{r globopt, echo=FALSE}
knitr::opts_chunk$set(fig.width=12) 
```

```{r mycss, results="asis", echo=FALSE}
cat('
<style type="text/css">
b, strong {color: red; }
i, em {color: blue; }
.defn {color: purple; }
.para {color: purple;
      font-weight: bold;
}
.figure { text-align: center; }
.caption { font-weight: bold; }
</style>
')
```

# Getting Started
Till now, the tissue-aware model has used the given cancer type (tissue) for training. But who says that those labels are good for grouping the samples? Here we cluster samples into "pseudo-tissues" and then fit the tissue-aware model. The number of clusters is the hyper-parameter that we need to tune to control the generalizatio error. For correct cross-validation, we do train-test split even before feature selection with Thresher. So, in essence, we run the whole pipeline of clustering and tissue-aware model fitting `nfold = 5` times. 
```{r , warning=FALSE}
rm(list=ls())
source("00-paths.R")

load(file.path(paths$clean, 'xena-tcga.Rda'))

tfdata <- tcga$tf
miRdata <- tcga$mir
mRNARest <- tcga$mrna


rm(tcga, cohorts)
```

# Cross-Validation for Model Complexity Selection

## Saving Train and Test Batches for Cross Validation
Adding fold variable to each sample and saving train/test portions for the whole analysis: 
```{r fold, warning = FALSE}
f <- file.path(paths$scratch, paste('train_batch_tpm_', 1, '.Rda', sep = ''))
nfolds <- 5
if (!file.exists(f)) {
  foldsId <- rep(1:nfolds, length.out = ncol(mRNARest))
  for (k in 1:nfolds) {
    print(paste("Fold", k, "started."))
    index <- which(foldsId == k)
    f <- file.path(paths$scratch, paste('train_batch_tpm_', k, '.Rda', sep = ''))
    g <- file.path(paths$scratch, paste('test_batch_tpm_', k, '.Rda', sep = ''))
  
  
    tfTrain <- tfdata[,-index]; tfTest <- tfdata[,index];
    mirTrain <- miRdata[,-index]; mirTest <- miRdata[,index];
    mrnaTrain <- mRNARest[,-index]; mrnaTest <- mRNARest[,index];
    
    save(tfTrain, mirTrain, mrnaTrain, file = f)
    save(tfTest, mirTest, mrnaTest, file = g)
  }
}
rm(mRNARest, miRdata, tfdata)
rm(mirTest, mirTrain, mrnaTest, mrnaTrain, tfTest, tfTrain, foldsId, f, g, index, k)
gc()
```

## Variable Selection with Thresher
Variable selection:
```{r tresh tfs, warning = FALSE}
suppressMessages( library(Thresher) ) # brings along PCDimension automatically

f <- file.path(paths$scratch, paste('thresh_reap_miR_tpm_', 5, '.Rda', sep = ''))

if (!file.exists(f)) {
  set.seed(47053)
  for (k in 1:nfolds) {
    print(paste("Fold", k, "threshing started."))
    load(file.path(paths$scratch, paste('train_batch_tpm_', k, '.Rda', sep = '')))
    rm(mrnaTrain)
    
    print(paste("Thresher for TFs"))
    startTime <- Sys.time()
    Thresh <- Thresher(t(tfTrain), method = "auer.gervini",
                       scale = TRUE, agfun = agDimTwiceMean)
    Reap <- Reaper(Thresh, useLoadings = TRUE, cutoff = 0.35, 
                   metric = NULL, linkage = "ward.D2", maxSampleGroups = 486)
    f <- file.path(paths$scratch, paste('thresh_reap_tf_tpm_', k, '.Rda', sep = ''))
    save(Thresh, Reap, file = f)
    print(Sys.time() - startTime)
    
    print(paste("Thresher for miRs"))
    startTime <- Sys.time()
    nonzero <- apply(mirTrain, 1, function(x) sum(x != 0))
    cutoff <- 0.25 * ncol(mirTrain)
    filteredMir <- mirTrain[nonzero > cutoff, ]

    Thresh <- Thresher(t(filteredMir), method = "auer.gervini",
                       scale = TRUE, agfun = agDimTwiceMean)
    Reap <- Reaper(Thresh, useLoadings = TRUE, cutoff = 0.35,
                   metric = NULL, linkage = "ward.D2", maxSampleGroups = 486)
    f <- file.path(paths$scratch, paste('thresh_reap_miR_tpm_', k, '.Rda', sep = ''))
    save(Thresh, Reap, file = f)
    print(Sys.time() - startTime)
  }
}
rm(f, Thresh, Reap, cutoff, nonzero, filteredMir, tfTrain, mirTrain)
gc()
```

## Medoid Computation
We need to save the medoids: 
```{r save tf mediods, warning = FALSE}

f <- file.path(paths$scratch, paste('medoids_mir_tpm_', 5, '.Rda', sep = ''))

if (!file.exists(f)) {
  set.seed(41053)
  for (k in 1:nfolds) {
    print(paste("Fold", k, "mediod finding started."))
    load(file.path(paths$scratch, paste('train_batch_tpm_', k, '.Rda', sep = '')))
    rm(mrnaTrain)
    
    load(file.path(paths$scratch, paste('thresh_reap_tf_tpm_', k, '.Rda', sep = '')))
    groups <- predict(Reap@fit)
    names(groups) <- rownames(tfTrain)[Reap@keep]
    NG <- Reap@nGroups
    tfMedoid <- matrix(0, ncol(tfTrain), NG)
    colnames(tfMedoid) <- 1:ncol(tfMedoid)
    d2MeanList <- list()
    for (I in 1:NG) {
      clusterExp <- tfTrain[names(groups)[groups == I], ]
      meanZeroClusterExp <- sweep(clusterExp, 2, apply(clusterExp, 2, mean))
      d2Mean <- apply(meanZeroClusterExp, 1, function(x) {sqrt(sum(x * x))})
      medoidGene <- rownames(clusterExp)[which.min(d2Mean)]
      tfMedoid[, I] <- as.numeric(tfTrain[medoidGene, ])
      colnames(tfMedoid)[I] <- medoidGene
      d2MeanList[[I]] <- d2Mean
    }
    rownames(tfMedoid) <- colnames(tfTrain)
    f <- file.path(paths$scratch, paste('medoids_tf_tpm_', k, '.Rda', sep = ''))
    save(tfMedoid, file = f)

    load(file.path(paths$scratch, paste('thresh_reap_miR_tpm_', k, '.Rda', sep = '')))
    nonzero <- apply(mirTrain, 1, function(x) sum(x != 0))
    cutoff <- 0.25 * ncol(mirTrain)
    filteredMir <- mirTrain[nonzero > cutoff, ]
    
    groups <- predict(Reap@fit)
    names(groups) <- rownames(filteredMir)[Reap@keep]
    NG <- Reap@nGroups
    mirMedoid <- matrix(0, ncol(filteredMir), NG)
    colnames(mirMedoid) <- 1:ncol(mirMedoid)
    d2MeanList <- list()
    for (I in 1:NG) {
      clusterExp <- filteredMir[names(groups)[groups == I], ]
      meanZeroClusterExp <- sweep(clusterExp, 2, apply(clusterExp, 2, mean))
      d2Mean <- apply(meanZeroClusterExp, 1, function(x) {sqrt(sum(x * x))})
      medoidGene <- rownames(clusterExp)[which.min(d2Mean)]
      mirMedoid[, I] <- as.numeric(filteredMir[medoidGene, ])
      colnames(mirMedoid)[I] <- medoidGene
      d2MeanList[[I]] <- d2Mean
    }  
    rownames(mirMedoid) <- colnames(filteredMir)
    f <- file.path(paths$scratch, paste('medoids_mir_tpm_', k, '.Rda', sep = ''))
    save(mirMedoid, file = f)
  }
}
rm(f, tfMedoid, mirMedoid, groups, NG, d2MeanList, clusterExp, meanZeroClusterExp, d2Mean, medoidGene)
rm(nonzero, startTime, I, k, cutoff)
```

## Cluster Aware Linear Model 
Next, we fit the linear models for each tissue after mean zeroing the outcome (this is equivalent to fit one model to all tissue and then fit the residuals of that model per tissue). 

### Train
First the training part:
```{r helpers, warning = FALSE, echo=FALSE}
library(ClassComparison)
library(oompaBase)

computeCor <- function(res, Y, ns=10^4){
  res <- as.matrix(res)
  Y <- as.matrix(Y)
  Yhat <- Y - res
  M <- nrow(Y)
  Ours <- sapply(1:M, function(i) cor(Y[i,], Yhat[i,]))
  
  Yind <- sample(1:M, ns, replace = T)
  YhatInd <- sample(1:M, ns, replace = T)
  ind <- cbind(Yind, YhatInd)
  ind <- ind[Yind != YhatInd, ]
  Null <- sapply(1:nrow(ind), function(j) cor(Y[ind[j,1],], Yhat[ind[j,2],]))
  z <- quantile(Null, .95, na.rm = T)
  acc <- sum(Ours > z, na.rm = T) / M
  return(list(ours=Ours, null=Null, acc=acc))
}


computeR2 <- function(res, Y){
  res <- as.matrix(res)
  Y <- as.matrix(Y)
  M <- ncol(Y)
  dmean <- matrixMean(Y)
  dvar <- as.vector(matrixVar(Y, dmean))
  ssres <- apply(res^2, 1, sum)
  r2 <- rep(0, M)
  # varInd <- dvar != 0
  # r2[varInd] <- 1 - ssres[varInd] / (dvar[varInd] * (M - 1))
  r2 <- 1 - ssres / (dvar * (M - 1))
  return(r2)
}

```

```{r training, warning = FALSE}
trainClusterAware <- function(X, Y, nc){
  X <- as.matrix(X)
  Y <- as.matrix(Y)
  coeffMatList <- list()
  N <- nrow(X); M <- nrow(Y); P <- ncol(X);
  res <- matrix(0, nrow = M, ncol = N)
  cat(paste("\n  Trianing with ", nc, " clusters:"))
  cat("\n    1) Clustering")
  myClust <- kmeans(X, nc, iter.max = 100, nstart = 100)
  assignment <- myClust$cluster

  cat("\n    2) Regression")
  cat("\n      Fitting OLS to clusters 1")
  for (cluster in 1:nc) {
    if(cluster %% 5 == 0) cat(paste(cluster)) else cat('.')
    coeffMat <- matrix(0, nrow = P + 1, ncol = M, 
                       dimnames = list(c('(Intercept)',
                                         gsub('\\-', '.', colnames(X))), 
                                         rownames(Y)))
    
    S <- (assignment == cluster) #Cluster Selector
    #remove constant covariates
    #reducing covariates is not important during model selection 
    #but shouldn't happen when learning the final model
    varCov <- apply(X[S,], 2, var) != 0
    mapping <- which(varCov)
    Xs <- X[S, varCov]
    Ys <- Y[, S]
    
    if (nrow(Xs) < ncol(Xs)) {
      #Not enough samples per cluster
      #Per-cluster average is our predictor
      #YcAvg is our predictions and the residuals are mean0Yc
      # pred[, S] <- matrix(rep(YcAvg, S), ncol = S)
      coeffMat[1,] <- apply(Ys, 1, mean)#YcAvg 
      res[, S] <- sweep(Ys, 1, coeffMat[1,])#mean0Yc 
    } else{
      tryCatch({
      mlm <- MultiLinearModel(Y ~ ., Xs, Ys)
      # pred[, S] <- t(mlm@predictions)
      # coeffMat[rownames(mlm@coefficients),] <- mlm@coefficients
      coeffMat[1,] <- mlm@coefficients[1, ]  # +1 to account for the '(Intercept)' row
      coeffMat[mapping + 1,] <- mlm@coefficients[-1, ]  # +1 to account for the '(Intercept)' row
      res[, S] <- Ys - t(mlm@predictions)
      }, error = function(e) {
          coeffMat[1,] <- apply(Ys, 1, mean)#YcAvg 
          res[, S] <- sweep(Ys, 1, coeffMat[1,])#mean0Yc 
      })
    }
    coeffMatList[[cluster]] <- coeffMat
  } 
  
  r2 <- computeR2(res, Y)
    
  # hist(r2, breaks=123)
  cat(paste("\n      Average R2:", round(mean(r2, na.rm =T), 2)))
  rmse <- sqrt((1/N) * apply(res^2, 1, sum))
  cat(paste("\n      Averge RMSE:", round(mean(rmse),2)))
  corr <- computeCor(res, Y)
  cat(paste("\n      Averge Cor:", round(mean(corr$acc),2)))
  
  trained <- list(coeffMatList=coeffMatList, nc=nc, 
                  res=res, r2=r2, rmse=rmse, corr=corr,
                  centers=myClust$centers)
  # save(trained, file = file.path(paths$scratch, paste('trained_tpm_', nc, '.Rda', sep = '')))
  
  return(trained)
}


```
Note that we do not save the whole MLM object, we just keep the coefficient matrix and the performance metrics that we keep track of: R2, RMSE, and Correlation of the prediction with outcome. We also keep the number of clusters and the cluster centers for the testing phase. 

### Test
Next testing: First for each new test data we find the closest cluster center from the training and then we use the corresponding linear model for prediction. Note that R2 here is not a valid measure because it may become arbitrarily small since any predictive model trained on training data can do worse than the test data mean. So we only compute RMSE and Correlation performances. 
 
```{r test, warning = FALSE}
testClusterAware <- function(X, Y, model){
  X <- as.matrix(X)
  Y <- as.matrix(Y)
  centers <- model$centers
  cat(paste("\n  Testing with ", nrow(centers), " clusters:"))
  M <- nrow(Y); N <- ncol(Y); #nrow(X) == N
  D <- matrix(0, nrow = N, ncol = nrow(centers))
  for(i in 1:nrow(centers)){
    center <- centers[i, ]
    D[,i] <- apply(X, 1, function(x) sum((x - center)^2))
  }
  C <- apply(D, 1, which.min)
  
  res <- matrix(0, nrow = M, ncol = N)
  aX <- cbind(rep(1, nrow(X)), X) #augmented X
  for(i in 1:nrow(centers)){
    res[, C==i] <- Y[,C==i] - t(aX[C==i, ] %*% model$coeffMatList[[i]])
  }
  rmse <- sqrt((1/N) * apply(res^2, 1, sum))
  cat(paste("\n    Averge RMSE:", round(mean(rmse),2)))
  corr <- computeCor(res, Y)
  # cat(paste("\n    Averge Cor:", round(mean(corr$acc),2)))
  cat(paste("\n    Averge Cor:", round((corr$acc),2)))


  tested <- list(res=res, rmse=rmse, corr=corr)
  # save(tested, file = file.path(paths$scratch, paste('tested_tpm_', model$nc, '.Rda', sep = '')))
  
  return(tested)
}
```

### Cross-Validation
Finally, we run the model:

```{r mirMLM, warning = FALSE}
nClusters <- c(1, 5, 10, 15, 20, 25, 30, 35)

f <- file.path(paths$scratch, paste('fold_', 5, '_kmeans_tpm_', 
                                          35, '.Rda', sep = ''))
if (!file.exists(f)) {
  set.seed(41053)
  cvTable <- matrix(0, nrow = nfolds, ncol = length(nClusters))

  for (k in 1:nfolds) {
    cat(paste("\nFold ", k, ": ", sep = ''))
    # Load Training Samples (tfTrain, mirTrain, mrnaTrain)
    load(file.path(paths$scratch, paste('train_batch_tpm_', k, '.Rda', sep = '')))
    rm(tfTrain, mirTrain)
    ## Global mean removal for Data Sharing
    Yavg <- apply(mrnaTrain, 1, mean)
    mean0Y <- sweep(mrnaTrain, 1, Yavg)
    ## Load Selected Features
    load(file.path(paths$scratch, paste('medoids_tf_tpm_', k, '.Rda', sep = '')))
    load(file.path(paths$scratch, paste('medoids_mir_tpm_', k, '.Rda', sep = '')))
    X <- cbind(tfMedoid, mirMedoid)
    cat(paste("Dimensions of X is", paste(dim(X), collapse = '*')))
    # Load Test Samples (tfTest, mirTest, mrnaTest)
    load(file.path(paths$scratch, paste('test_batch_tpm_', k, '.Rda', sep = '')))
    ## Prepare Test Features (match with the selected features of training set)
    tfTestMedoid <- t(tfTest[colnames(tfMedoid), ])
    mirTestMedoid <- t(mirTest[colnames(mirMedoid),])
    Xt <- cbind(tfTestMedoid, mirTestMedoid)
    mean0Yt <- sweep(mrnaTest, 1, Yavg)
    
    cnt <- 0
    for(nc in nClusters){
      cnt <- cnt + 1
      #Train
      learned <- trainClusterAware(X, mean0Y, nc)
      #Test
      tested <- testClusterAware(Xt, mean0Yt, learned)
      #Save
      cvTable[k, cnt] <- mean(tested$rmse)
      f <- file.path(paths$scratch, paste('fold_', k, '_kmeans_tpm_', 
                                          nc, '.Rda', sep = ''))
      cat(paste("\nSaving results of", nc, "clusters for fold", k))
      save(learned, tested, file = f)
    }
  }
}

rm(f, cvTable, tested, learned, cnt, mean0Yt, Xt, mirTestMedoid, tfTestMedoid, X, mean0Y, Yavg)
rm(nc, k, cnt, tfMedoid, mirMedoid, tfTest, mrnaTrain, mrnaTest, mirTest)
gc()
```

Let's take a look at the train and test results. 

```{r r2res, warning = FALSE}
g <- file.path(paths$scratch, 'cvTables_tpm.Rda')
if (file.exists(g)) {
  load(g)
} else{
  cvR2Trn <- cvCorrTst <- cvCorrTrn <- cvRmseTst <- cvRmseTrn <- matrix(0, nrow = nfolds, ncol = length(nClusters))
  colnames(cvR2Trn) <- colnames(cvCorrTst) <- colnames(cvRmseTst) <- paste("nc", nClusters, sep = '-')
  
  cnt <- 0
  for(nc in nClusters){
    cnt <- cnt + 1
    cat(paste("\nNumber of clusters:", nc, "Folds"))
    for (k in 1:nfolds) {
      cat(paste(" ", k))
      f <- file.path(paths$scratch, paste('fold_', k, '_kmeans_tpm_', 
                                            nc, '.Rda', sep = ''))
      load(file = f)
      # print(summary(learned$r2))
      # hist(learned$r2, breaks=234, 
      #      main=paste("Number of Clusters=", nc, ",Fold=", k, 
      #                 ",Average R2=", round(stat['Mean'],2)),
      #      xlab = "R2")
      cvR2Trn[k, cnt] <- mean(learned$r2, na.rm=TRUE)
      cvRmseTst[k, cnt] <- mean(tested$rmse)
      cvRmseTrn[k, cnt] <- mean(learned$rmse) 
      cvCorrTst[k, cnt] <- mean(tested$corr$acc)
      cvCorrTrn[k, cnt] <- mean(learned$corr$acc)
    }
  }
  save(cvR2Trn, cvCorrTst, cvCorrTrn, cvRmseTst, cvRmseTrn, file=g)
}

print("R2 during training:")
print(cvR2Trn)
print(paste("Average train R2:", paste(round(apply(cvR2Trn, 2, mean),3) , collapse = ',')))

print("RMSE for training:")
print(cvRmseTst)
print(paste("Best number of clusters according to RMSE:", colnames(cvRmseTst)[which.min(apply(cvRmseTst, 2, mean))]))
print(paste("Average test RMSE:", paste(round(apply(cvRmseTst, 2, mean),3), collapse = ',')))

print("Corr for training:")
print(cvCorrTst)
print(paste("Best number of clusters according to Correlation:", colnames(cvCorrTst)[which.max(apply(cvCorrTst, 2, mean))]))
print(paste("Average test Corr:", paste(round(apply(cvCorrTst, 2, mean),4), collapse = ',')))

rm(cnt, f)
```
So the best test performance corresponds to 15 clusters. 
For 15 clusters, we get average of 62% R2 on training, which is pretty good! The test correlation performance is also excellent at 0.9056! 

```{r plot, warning = FALSE}
library(ggplot2)

plot.cv <- function(cvtrain, cvtest, ytext){
  yt <- colMeans(cvtest)
  et <- apply(cvtest, 2, sd)
  
  yn <- colMeans(cvtrain)
  en <- apply(cvtrain, 2, sd)
  
  toplot <- data.frame(yt = yt,et = et,yn = yn,en = en,nc = nClusters)
  
  ggplot(toplot) +
    geom_line(aes(x = nc, y = yt, col = "Test"), size = 1) +
    geom_point(aes(x = nc, y = yt, shape = 'a'), show.legend = FALSE) +
    geom_line(aes(x = nc, y = yn, col = "Train"), size = 1) +
    geom_point(aes(x = nc, y = yn, shape = 'c'), show.legend = FALSE) +
    geom_errorbar(aes(x = nc,ymin = yt - et,ymax = yt + et), width = 0.5) +
    geom_errorbar(aes(x = nc,ymin = yn - en,ymax = yn + en), width = 0.5) +
    theme_bw() + xlab("Number of Clusters") + ylab(ytext) +
    scale_color_manual(values = c("red", "green"), name = "")
}

load(file.path(paths$scratch, 'cvTables_tpm.Rda'))

rmse_plot <- plot.cv(cvRmseTrn, cvRmseTst, "RMSE")
corr_plot <- plot.cv(cvCorrTrn, cvCorrTst, "Correlation")

ggsave(filename = file.path(paths$figures, "rmse_plot.png"), plot = rmse_plot, width = 10, height = 6, dpi = 300)
ggsave(filename = file.path(paths$figures, "corr_plot.png"), plot = corr_plot, width = 10, height = 6, dpi = 300)


toplotr2 <- data.frame(yt = colMeans(cvR2Trn),
                       et = apply(cvR2Trn, 2, sd),nc = nClusters)
ggplot(toplotr2) +
    geom_line(aes(x = nc, y = yt), size = 1) +
    geom_point(aes(x = nc, y = yt, shape = 'a'), show.legend = FALSE) +
    geom_errorbar(aes(x = nc,ymin = yt - et,ymax = yt + et), width = 0.5) +
    theme_bw() + xlab("Number of Clusters") + ylab("Average R2") 

rm(toplotr2, cvRmseTst, cvRmseTrn, cvCorrTrn, cvCorrTst, cvR2Trn)
```

# Learning the Final Model Using All of Data 
Now that we have selected the model complexity through CV, we train a single model using all of data to be used in the transportability experiment. 

## Load the Relevant Data
```{r bigModel, warning = FALSE}
load(file.path(paths$clean, 'xena-tcga.Rda'))

tfdata <- tcga$tf
miRdata <- tcga$mir
# We don't care to remove constant mRNAs because there is no R^2 to compute here. 
mRNARest <- tcga$mrna


rm(tcga)
```

## Thresher
```{r all thresher, warning = FALSE}
suppressMessages( library(Thresher) ) # brings along PCDimension automatically

f <- file.path(paths$scratch, paste('thresh_reap_tf_all_tpm.Rda', sep = ''))
g <- file.path(paths$scratch, paste('thresh_reap_miR_all_tpm.Rda', sep = ''))


if (!file.exists(f)) {
  set.seed(47053)
  print(paste("Thresher for TFs"))
  Thresh <- Thresher(t(tfdata), method = "auer.gervini",
                     scale = TRUE, agfun = agDimTwiceMean)
  Reap <- Reaper(Thresh, useLoadings = TRUE, cutoff = 0.35, 
                 metric = NULL, linkage = "ward.D2", maxSampleGroups = 486)
  save(Thresh, Reap, file = f)

  print(paste("Thresher for miRs"))
  nonzero <- apply(miRdata, 1, function(x) sum(x != 0))
  cutoff <- 0.2 * ncol(miRdata)
  filteredMir <- miRdata[nonzero > cutoff, ]

  Thresh <- Thresher(t(filteredMir), method = "auer.gervini",
                     scale = TRUE, agfun = agDimTwiceMean)
  Reap <- Reaper(Thresh, useLoadings = TRUE, cutoff = 0.35,
                 metric = NULL, linkage = "ward.D2", maxSampleGroups = 486)
  save(Thresh, Reap, file = g)
}

```

## Medoid

```{r all Medoids, warning = FALSE}
f <- file.path(paths$scratch, paste('medoids_tf_all_tpm.Rda', sep = ''))
g <- file.path(paths$scratch, paste('medoids_mir_all_tpm.Rda', sep = ''))

if (!file.exists(f)) {
  set.seed(41053)
  load(file.path(paths$scratch, paste('thresh_reap_tf_all_tpm.Rda', sep = '')))
  groups <- predict(Reap@fit)
  names(groups) <- rownames(tfdata)[Reap@keep]
  NG <- Reap@nGroups
  tfMedoid <- matrix(0, ncol(tfdata), NG)
  colnames(tfMedoid) <- 1:ncol(tfMedoid)
  d2MeanList <- list()
  for (I in 1:NG) {
    clusterExp <- tfdata[names(groups)[groups == I], ]
    meanZeroClusterExp <- sweep(clusterExp, 2, apply(clusterExp, 2, mean))
    d2Mean <- apply(meanZeroClusterExp, 1, function(x) {sqrt(sum(x * x))})
    medoidGene <- rownames(clusterExp)[which.min(d2Mean)]
    tfMedoid[, I] <- as.numeric(tfdata[medoidGene, ])
    colnames(tfMedoid)[I] <- medoidGene
    names(d2Mean) <- rownames(clusterExp)
    d2MeanList[[I]] <- d2Mean
  }
  rownames(tfMedoid) <- colnames(tfdata)
  save(tfMedoid, file = f)
  h <- file.path(paths$scratch, paste('d2MeanList_tf_all_tpm.Rda', sep = ''))
  save(d2MeanList, file = h)



  load(file.path(paths$scratch, paste('thresh_reap_miR_all_tpm.Rda', sep = '')))
  nonzero <- apply(miRdata, 1, function(x) sum(x != 0))
  cutoff <- 0.2 * ncol(miRdata)
  filteredMir <- miRdata[nonzero > cutoff, ]
  
  groups <- predict(Reap@fit)
  names(groups) <- rownames(filteredMir)[Reap@keep]
  NG <- Reap@nGroups
  mirMedoid <- matrix(0, ncol(filteredMir), NG)
  colnames(mirMedoid) <- 1:ncol(mirMedoid)
  d2MeanList <- list()
  for (I in 1:NG) {
    clusterExp <- filteredMir[names(groups)[groups == I], ]
    meanZeroClusterExp <- sweep(clusterExp, 2, apply(clusterExp, 2, mean))
    d2Mean <- apply(meanZeroClusterExp, 1, function(x) {sqrt(sum(x * x))})
    medoidGene <- rownames(clusterExp)[which.min(d2Mean)]
    mirMedoid[, I] <- as.numeric(filteredMir[medoidGene, ])
    colnames(mirMedoid)[I] <- medoidGene
    names(d2Mean) <- rownames(clusterExp)
    d2MeanList[[I]] <- d2Mean
  }
  rownames(mirMedoid) <- colnames(filteredMir)
  save(mirMedoid, file = g)
  h <- file.path(paths$scratch, paste('d2MeanList_mir_all_tpm.Rda', sep = ''))
  save(d2MeanList, file = h)
  
} else{
  load(f)
  load(g)
}
rm(f, groups, NG, d2MeanList, clusterExp, meanZeroClusterExp, d2Mean, medoidGene)
rm(nonzero, startTime, I, k, cutoff, filteredMir, miRdata, Reap, Thresh, tfdata)

```

## Regression
```{r , warning = FALSE}
nc <- 15
f <- file.path(paths$scratch, paste('final_model_tpm_', nc, '.Rda', sep = ''))
if (!file.exists(f)) {
  Yavg <- as.matrix(apply(mRNARest, 1, mean))
  Y <- as.matrix(sweep(mRNARest, 1, Yavg))
  X <- as.matrix(cbind(tfMedoid, mirMedoid))
  
  coeffMatList <- list()
  N <- nrow(X); M <- nrow(Y); P <- ncol(X);
  res <- matrix(0, nrow = M, ncol = N)
  
  cat(paste("\n  Learning a model with ", nc, " clusters:"))
  cat("\n    1) Clustering")
  myClust <- kmeans(X, nc, iter.max = 100, nstart = 100)
  assignment <- myClust$cluster

  cat("\n    2) Regression")
  cat("\n      Fitting OLS to clusters 1")
  
  for (cluster in 1:nc) {
    if(cluster %% 5 == 0) cat(paste(cluster)) else cat('.')
    coeffMat <- matrix(0, nrow = P + 1, ncol = M, 
                       dimnames = list(c('(Intercept)',
                                         gsub('\\-', '.', colnames(X))), 
                                         rownames(Y)))
    
    S <- (assignment == cluster) #Cluster Selector
    varCov <- apply(X[S,], 2, var) != 0
    Xs <- X[S, varCov]
     # Create a mapping from variable genes to their positions in the original data
    mapping <- which(varCov)
    Ys <- Y[, S]
    
    if (nrow(Xs) < ncol(Xs)) {
      print("Not enough samples, using the means.")
      coeffMat[1,] <- apply(Ys, 1, mean)#YcAvg 
      res[, S] <- sweep(Ys, 1, coeffMat[1,])#mean0Yc 
    } else{
      mlm <- MultiLinearModel(Y ~ ., Xs, Ys)
      # Update the coeffMat only for variable genes, leaving others as zero
      coeffMat[1,] <- mlm@coefficients[1, ]  # +1 to account for the '(Intercept)' row
      coeffMat[mapping + 1,] <- mlm@coefficients[-1, ]  # +1 to account for the '(Intercept)' row
      res[, S] <- Ys - t(mlm@predictions)
    }
    coeffMatList[[cluster]] <- coeffMat
  } 
  
  r2 <- computeR2(res, Y)
  cat(paste("\n      Average R2:", round(mean(r2, na.rm =T), 2)))
  rmse <- sqrt((1/N) * apply(res^2, 1, sum))
  cat(paste("\n      Averge RMSE:", round(mean(rmse),2)))
  corr <- computeCor(res, Y)
  cat(paste("\n      Averge Cor:", round(mean(corr$acc),2)))
  
  model <- list(coeffMatList=coeffMatList, nc=nc,
                  res=res, r2=r2, rmse=rmse, corr=corr,
                  centers=myClust$centers, alpha=Yavg)
  # model <- list(coeffMatList=coeffMatList, nc=nc, 
  #                 res=res, r2=r2, rmse=rmse, corr=corr,
  #                 centers=myClust$medoids, alpha=Yavg)
  save(model, file = f)
} else {
  load(f)
}

hist(model$r2, breaks=123, main="R2", xlab=paste("Average R2 =", round(mean(model$r2, na.rm =T), 2)))
print(paste("\n      Average R2:", round(mean(model$r2, na.rm =T), 2)))
rm(coeffMat, coeffMatList, mlm, res, r2, rmse, corr, Yavg, myClust, Y, Ys, X, Xs)
```



# Appendix

This analysis was performed using the following R packages.
```{r si}
sessionInfo()

```




